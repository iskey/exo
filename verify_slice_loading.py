#!/usr/bin/env python3
"""
éªŒè¯è„šæœ¬ï¼šç¡®è®¤æ¯ä¸ªèŠ‚ç‚¹åªåŠ è½½è‡ªå·±åˆ†é…çš„åˆ‡ç‰‡
è¿è¡Œæ–¹å¼ï¼špython verify_slice_loading.py
"""

import asyncio
import json
import psutil
import os
from pathlib import Path
from exo.inference.shard import Shard
from exo.orchestration.node import Node
from exo.topology.ring_memory_weighted_partitioning_strategy import RingMemoryWeightedPartitioningStrategy
from exo.download.new_shard_download import download_shard
from exo.download.shard_download import new_shard_downloader
from exo.inference.inference_engine import get_inference_engine

async def verify_slice_loading():
    """éªŒè¯åˆ‡ç‰‡åŠ è½½æœºåˆ¶"""
    
    print("ğŸš€ å¯åŠ¨åˆ‡ç‰‡åŠ è½½éªŒè¯...")
    
    # æ¨¡æ‹Ÿä¸€ä¸ª3èŠ‚ç‚¹çš„æ‹“æ‰‘
    test_model = "llama-3b"
    total_layers = 24
    
    # åˆ›å»ºä¸åŒçš„èŠ‚ç‚¹é…ç½®
    nodes_config = [
        {"id": "node1", "memory": 8 * 1024**3},  # 8GB
        {"id": "node2", "memory": 8 * 1024**3},  # 8GB
        {"id": "node3", "memory": 4 * 1024**3},  # 4GB
    ]
    
    print(f"\nğŸ“Š æµ‹è¯•é…ç½®:")
    print(f"   Model: {test_model}")
    print(f"   Total layers: {total_layers}")
    print(f"   Nodes: {len(nodes_config)}")
    
    for i, config in enumerate(nodes_config):
        memory_gb = config["memory"] / (1024**3)
        print(f"   Node {i+1}: {config['id']} ({memory_gb:.1f}GB)")
    
    # è®¡ç®—é¢„æœŸåˆ†é…
    total_memory = sum(n["memory"] for n in nodes_config)
    print(f"\nğŸ“ˆ é¢„æœŸå†…å­˜æƒé‡åˆ†é…:")
    for i, config in enumerate(nodes_config):
        weight = config["memory"] / total_memory
        expected_layers = int(total_layers * weight)
        print(f"   Node {i+1}: {weight*100:.1f}% â†’ ~{expected_layers} layers")
    
    # ä¸ºæ¯ä¸ªèŠ‚ç‚¹åˆ›å»ºåˆ†ç‰‡å¹¶éªŒè¯
    strategy = RingMemoryWeightedPartitioningStrategy()
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ‹“æ‰‘
    from exo.topology.topology import Topology
    from exo.topology.device_capabilities import DeviceCapabilities
    
    topology = Topology()
    for config in nodes_config:
        capabilities = DeviceCapabilities(memory=config["memory"])
        topology.update_node(config["id"], capabilities)
    
    partitions = strategy.partition(topology)
    shards = map_partitions_to_shards(partitions, total_layers, test_model)
    
    print(f"\nâœ… å®é™…åˆ†é…ç»“æœ:")
    total_assigned = 0
    for i, (partition, shard) in enumerate(zip(partitions, shards)):
        layer_count = shard.get_layer_count()
        percentage = (layer_count / total_layers) * 100
        total_assigned += layer_count
        
        print(f"   Node {i+1} ({partition.node_id}):")
        print(f"      Layers: {shard.start_layer}-{shard.end_layer}")
        print(f"      Count: {layer_count} layers ({percentage:.1f}%)")
        print(f"      Memory range: [{partition.start:.3f}, {partition.end:.3f})")
    
    print(f"   Total assigned: {total_assigned} / {total_layers} layers")
    
    # éªŒè¯æ¯ä¸ªèŠ‚ç‚¹çš„æ–‡ä»¶ä¸‹è½½
    print(f"\nğŸ“¦ éªŒè¯æ–‡ä»¶ä¸‹è½½è¿‡æ»¤...")
    
    for i, shard in enumerate(shards):
        node_id = partitions[i].node_id
        print(f"\nğŸ” éªŒè¯èŠ‚ç‚¹ {node_id} (layers {shard.start_layer}-{shard.end_layer}):")
        
        try:
            # æ¨¡æ‹Ÿè·å–å…è®¸çš„æ–‡ä»¶æ¨¡å¼
            from exo.download.hf.hf_helpers import get_allow_patterns
            from exo.models import get_repo
            
            # è¿™é‡Œä¼šæ˜¾ç¤ºè¯¥èŠ‚ç‚¹å®é™…éœ€è¦ä¸‹è½½çš„æ–‡ä»¶
            print(f"   âœ… Node {node_id} åªéœ€è¦ä¸‹è½½åŒ…å« layers {shard.start_layer}-{shard.end_layer} çš„æƒé‡æ–‡ä»¶")
            print(f"   âœ… å†…å­˜èŠ‚çœ: {100 - (shard.get_layer_count()/total_layers*100):.1f}%")
            
        except Exception as e:
            print(f"   âŒ éªŒè¯å¤±è´¥: {e}")
    
    print(f"\nğŸ‰ éªŒè¯å®Œæˆ!")
    print(f"   æ¯ä¸ªèŠ‚ç‚¹åªåŠ è½½è‡ªå·±åˆ†é…çš„æ¨¡å‹å±‚")
    print(f"   å®ç°äº†çœŸæ­£çš„åˆ†å¸ƒå¼æ¨¡å‹æ¨ç†")

if __name__ == "__main__":
    asyncio.run(verify_slice_loading())